# airflow-dataops-cours/dags/mon_premier_dag.py
from __future__ import annotations

import pendulum # Librairie pour g√©rer les dates et heures

from airflow.models.dag import DAG
from airflow.operators.bash import BashOperator

with DAG(
    dag_id="mon_premier_dag_v1", # Identifiant unique de votre DAG
    start_date=pendulum.datetime(2024, 1, 1, tz="UTC"), # Date de d√©but (dans le pass√©)
    catchup=False, # Ne pas essayer de rattraper les ex√©cutions pass√©es
    schedule=None, # Pas de planification automatique, d√©clenchement manuel
    tags=["test", "cours_dataops"], # Pour organiser/filtrer les DAGs dans l'UI
) as dag:
    tache_hello_airflow = BashOperator(
        task_id="dire_bonjour_airflow", # Identifiant unique de la t√¢che
        bash_command='echo "Bonjour Airflow, je fonctionne dans Docker ! üéâ Date: $(date)"',
    )
